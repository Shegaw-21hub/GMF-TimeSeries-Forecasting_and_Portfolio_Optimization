{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv_tf (Python 3.10.0)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'd:/Project/GMF-TimeSeries-Forecasting_and_Portfolio_Optimization/venv_tf/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Cell 1: ARIMA Code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if data is loaded before proceeding\n",
    "try:\n",
    "    data = pd.read_csv('../data/processed/daily_returns.csv', index_col=0, parse_dates=True)\n",
    "except FileNotFoundError:\n",
    "    print(\"Preprocessed data not found. Please run the EDA notebook first.\")\n",
    "    data = None\n",
    "\n",
    "if data is not None:\n",
    "    # Use pmdarima to find the best ARIMA parameters\n",
    "    from pmdarima import auto_arima\n",
    "\n",
    "    tsla_returns = data['Adj Close_TSLA'].dropna()\n",
    "    print(\"\\nTraining ARIMA model on TSLA daily returns...\")\n",
    "\n",
    "    # The 'd' parameter is set to 0 because returns are stationary\n",
    "    arima_model = auto_arima(tsla_returns, start_p=1, start_q=1,\n",
    "                            max_p=5, max_q=5, m=1,\n",
    "                            start_P=0, seasonal=False,\n",
    "                            d=0, trace=True,\n",
    "                            error_action='ignore',\n",
    "                            suppress_warnings=True,\n",
    "                            stepwise=True)\n",
    "\n",
    "    print(\"\\nARIMA Model Summary:\")\n",
    "    print(arima_model.summary())\n",
    "\n",
    "    # Forecast future returns (e.g., 60 trading days)\n",
    "    n_periods = 60\n",
    "    forecast, conf_int = arima_model.predict(n_periods=n_periods, return_conf_int=True)\n",
    "\n",
    "    # Convert forecast to a pandas series with a future date index\n",
    "    forecast_index = pd.date_range(start=tsla_returns.index[-1], periods=n_periods + 1, freq='B')[1:]\n",
    "    forecast_series = pd.Series(forecast, index=forecast_index)\n",
    "    conf_int_df = pd.DataFrame(conf_int, index=forecast_index, columns=['lower_bound', 'upper_bound'])\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(tsla_returns[-180:], label='Historical Returns')\n",
    "    plt.plot(forecast_series, label='ARIMA Forecast', color='red')\n",
    "    plt.fill_between(conf_int_df.index, conf_int_df['lower_bound'], conf_int_df['upper_bound'], color='pink', alpha=0.3, label='Confidence Interval')\n",
    "    plt.title('TSLA Daily Returns: ARIMA Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Daily Return')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: LSTM Code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if data is loaded before proceeding\n",
    "try:\n",
    "    data = pd.read_csv('../data/processed/daily_returns.csv', index_col=0, parse_dates=True)\n",
    "except FileNotFoundError:\n",
    "    print(\"Preprocessed data not found. Please run the EDA notebook first.\")\n",
    "    data = None\n",
    "\n",
    "if data is not None:\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "    tsla_returns = data['Adj Close_TSLA'].values.reshape(-1, 1)\n",
    "\n",
    "    # Normalize the data for the LSTM\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(tsla_returns)\n",
    "\n",
    "    # Create a function to convert the time series into a supervised learning problem\n",
    "    def create_dataset(dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset) - look_back - 1):\n",
    "            a = dataset[i:(i + look_back), 0]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back, 0])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    # Split into training and testing sets\n",
    "    train_size = int(len(scaled_data) * 0.8)\n",
    "    train_data = scaled_data[0:train_size, :]\n",
    "    test_data = scaled_data[train_size:len(scaled_data), :]\n",
    "\n",
    "    # Reshape the data for the LSTM model\n",
    "    look_back = 60\n",
    "    X_train, y_train = create_dataset(train_data, look_back)\n",
    "    X_test, y_test = create_dataset(test_data, look_back)\n",
    "\n",
    "    # Reshape input to be [samples, time steps, features]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Build the LSTM model\n",
    "    print(\"\\nBuilding and training the LSTM model...\")\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=(look_back, 1)))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=64, verbose=1)\n",
    "\n",
    "    # Make predictions\n",
    "    train_predict = model.predict(X_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform predictions to original scale\n",
    "    train_predict = scaler.inverse_transform(train_predict)\n",
    "    test_predict = scaler.inverse_transform(test_predict)\n",
    "    y_train = scaler.inverse_transform([y_train])\n",
    "    y_test = scaler.inverse_transform([y_test])\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(scaler.inverse_transform(scaled_data), label='Original Returns')\n",
    "    plt.plot(np.arange(look_back, len(train_predict) + look_back), train_predict, label='Training Prediction', color='green')\n",
    "    plt.plot(np.arange(len(train_predict) + (2 * look_back) + 1, len(scaled_data) - 1), test_predict, label='Testing Prediction', color='red')\n",
    "    plt.title('TSLA Daily Returns: LSTM Model Predictions')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Daily Return')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_arima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
